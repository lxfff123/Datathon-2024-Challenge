{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss7CKuDuefEc",
        "outputId": "4c06e7cf-3604-4d26-dd1c-650d9d517ed0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, make_scorer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Import models for comparison\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier,\n",
        "    HistGradientBoostingClassifier\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Load data\n",
        "def load_data(train_path, test_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "    test = pd.read_csv(test_path)\n",
        "    return train, test\n",
        "\n",
        "# Separate features and target variable\n",
        "def preprocess_data(train, test, target_column='DiagPeriodL90D'):\n",
        "    X = train.drop(columns=[target_column, 'patient_id'])\n",
        "    y = train[target_column]\n",
        "    X_test = test.drop(columns=['patient_id'])\n",
        "    return X, y, X_test\n",
        "\n",
        "# Define preprocessors\n",
        "def create_preprocessor(X):\n",
        "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "    return preprocessor\n",
        "\n",
        "# Initialize models\n",
        "def initialize_models():\n",
        "    return {\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "        'CatBoost': CatBoostClassifier(verbose=0, random_state=42),\n",
        "        'LightGBM': LGBMClassifier(random_state=42),\n",
        "        'SVC': SVC(probability=True, random_state=42),\n",
        "        'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "        'GaussianNB': GaussianNB(),\n",
        "        'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
        "        'HistGradientBoosting': HistGradientBoostingClassifier(random_state=42),\n",
        "        'Voting Classifier': VotingClassifier(estimators=[\n",
        "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "            ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "            ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
        "            ('cat', CatBoostClassifier(verbose=0, random_state=42)),\n",
        "            ('lgb', LGBMClassifier(random_state=42))\n",
        "        ], voting='soft')\n",
        "    }\n",
        "\n",
        "# Evaluate models\n",
        "def evaluate_models(models, preprocessor, X, y, n_splits=5):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
        "        cv_scores = cross_val_score(pipeline, X, y, cv=skf, scoring=scorer, n_jobs=-1)\n",
        "        results[name] = {\n",
        "            'Mean ROC-AUC': cv_scores.mean(),\n",
        "            'Std Dev': cv_scores.std(),\n",
        "            'Scores': cv_scores\n",
        "        }\n",
        "        print(f\"{name}: Mean ROC-AUC = {cv_scores.mean():.4f}, Std = {cv_scores.std():.4f}\")\n",
        "    return pd.DataFrame(results).T\n",
        "\n",
        "# Train best model on full data and make predictions\n",
        "def train_best_model_and_predict(best_model_name, models, preprocessor, X, y, X_test, test_data):\n",
        "    best_model = models[best_model_name]\n",
        "    final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', best_model)])\n",
        "    final_pipeline.fit(X, y)\n",
        "\n",
        "    predictions = final_pipeline.predict_proba(X_test)[:, 1]  # Probability of DiagPeriodL90D=1\n",
        "    submission = pd.DataFrame({\n",
        "        'patient_id': test_data['patient_id'],\n",
        "        'DiagPeriodL90D': predictions\n",
        "    })\n",
        "    submission.to_csv('submission.csv', index=False)\n",
        "    print(f\"Submission file created as 'submission.csv' with best model: {best_model_name}\")"
      ],
      "metadata": {
        "id": "KIQtyV4NeZdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64a0eb7-859b-487e-92f4-9942617a9af2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier  # Ensuring this is imported if used\n",
        "\n",
        "# Custom transformer to convert sparse matrix to dense matrix\n",
        "class SparseToDenseTransformer(TransformerMixin, BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.toarray() if hasattr(X, 'toarray') else X\n",
        "\n",
        "# Function to check if model needs dense data\n",
        "def needs_dense_data(model):\n",
        "    # Add models that require dense data here\n",
        "    return isinstance(model, (GaussianNB, HistGradientBoostingClassifier))\n",
        "\n",
        "# Adjusted evaluate_models function\n",
        "def evaluate_models(models, preprocessor, X, y, n_splits=5):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        if needs_dense_data(model):\n",
        "            # Wrap models needing dense data with SparseToDenseTransformer\n",
        "            pipeline = Pipeline(steps=[\n",
        "                ('preprocessor', preprocessor),\n",
        "                ('to_dense', SparseToDenseTransformer()),\n",
        "                ('classifier', model)\n",
        "            ])\n",
        "        else:\n",
        "            # Standard pipeline without conversion for other models\n",
        "            pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
        "\n",
        "        # Evaluate using cross-validation\n",
        "        cv_scores = cross_val_score(pipeline, X, y, cv=skf, scoring=scorer, n_jobs=-1)\n",
        "\n",
        "        results[name] = {\n",
        "            'Mean ROC-AUC': cv_scores.mean(),\n",
        "            'Std Dev': cv_scores.std(),\n",
        "            'Scores': cv_scores\n",
        "        }\n",
        "        print(f\"{name}: Mean ROC-AUC = {cv_scores.mean():.4f}, Std = {cv_scores.std():.4f}\")\n",
        "\n",
        "    return pd.DataFrame(results).T"
      ],
      "metadata": {
        "id": "LAs_lnbCgaDY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Paths to data files\n",
        "    train_path = 'processed_train_data.csv'\n",
        "    test_path = 'processed_test_data.csv'\n",
        "\n",
        "    # Load datasets\n",
        "    train_data, test_data = load_data(train_path, test_path)\n",
        "\n",
        "    # Preprocess data\n",
        "    X, y, X_test = preprocess_data(train_data, test_data)\n",
        "\n",
        "    # Create preprocessor\n",
        "    preprocessor = create_preprocessor(X)\n",
        "\n",
        "    # Initialize models\n",
        "    models = initialize_models()\n",
        "\n",
        "    # Evaluate models and get results\n",
        "    model_results = evaluate_models(models, preprocessor, X, y)\n",
        "\n",
        "    # Select the best model by highest ROC-AUC mean\n",
        "    best_model_name = model_results['Mean ROC-AUC'].idxmax()\n",
        "    print(f\"\\nBest model: {best_model_name} with Mean ROC-AUC: {model_results['Mean ROC-AUC'].max():.4f}\")\n",
        "\n",
        "    # Train the best model and predict on test set\n",
        "    train_best_model_and_predict(best_model_name, models, preprocessor, X, y, X_test, test_data)\n"
      ],
      "metadata": {
        "id": "jZQ7z7BXgfeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee988846-265b-4cb3-9920-c2518026587a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Mean ROC-AUC = 0.7606, Std = 0.0051\n",
            "Random Forest: Mean ROC-AUC = 0.7841, Std = 0.0042\n",
            "Gradient Boosting: Mean ROC-AUC = 0.7993, Std = 0.0038\n",
            "XGBoost: Mean ROC-AUC = 0.7965, Std = 0.0045\n",
            "CatBoost: Mean ROC-AUC = 0.8026, Std = 0.0044\n",
            "LightGBM: Mean ROC-AUC = 0.7969, Std = 0.0058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC: Mean ROC-AUC = 0.7598, Std = 0.0032\n",
            "K-Nearest Neighbors: Mean ROC-AUC = 0.6191, Std = 0.0055\n",
            "GaussianNB: Mean ROC-AUC = 0.5963, Std = 0.0064\n",
            "Extra Trees: Mean ROC-AUC = 0.7712, Std = 0.0039\n",
            "HistGradientBoosting: Mean ROC-AUC = 0.8023, Std = 0.0049\n",
            "Voting Classifier: Mean ROC-AUC = 0.8004, Std = 0.0046\n",
            "\n",
            "Best model: CatBoost with Mean ROC-AUC: 0.8026\n",
            "Submission file created as 'submission.csv' with best model: CatBoost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for Gradient Boosting\n",
        "param_grid = {\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__max_depth': [3, 5, 7],\n",
        "    'classifier__learning_rate': [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "# Create a GradientBoostingClassifier instance\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create a pipeline with the preprocessor and GradientBoostingClassifier\n",
        "gb_pipeline = Pipeline([('preprocessor', preprocessor), ('classifier', gb_model)])\n",
        "\n",
        "# Perform GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(gb_pipeline, param_grid, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the results for each hyperparameter combination\n",
        "print(\"Gradient Boosting Hyperparameter Tuning Results:\")\n",
        "results = pd.DataFrame(grid_search.cv_results_)\n",
        "print(results[['params', 'mean_test_score', 'std_test_score']])\n",
        "\n",
        "\n",
        "# Get the best hyperparameters and score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"\\nBest Hyperparameters: {best_params}\")\n",
        "print(f\"Best Mean ROC-AUC Score: {best_score:.4f}\")"
      ],
      "metadata": {
        "id": "3w7PvhFZklfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64fd8fd-6698-4d8b-d245-515af1490566"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Hyperparameter Tuning Results:\n",
            "                                               params  mean_test_score  \\\n",
            "0   {'classifier__learning_rate': 0.01, 'classifie...         0.758230   \n",
            "1   {'classifier__learning_rate': 0.01, 'classifie...         0.758230   \n",
            "2   {'classifier__learning_rate': 0.01, 'classifie...         0.758236   \n",
            "3   {'classifier__learning_rate': 0.01, 'classifie...         0.768243   \n",
            "4   {'classifier__learning_rate': 0.01, 'classifie...         0.768254   \n",
            "5   {'classifier__learning_rate': 0.01, 'classifie...         0.768250   \n",
            "6   {'classifier__learning_rate': 0.01, 'classifie...         0.786525   \n",
            "7   {'classifier__learning_rate': 0.01, 'classifie...         0.786712   \n",
            "8   {'classifier__learning_rate': 0.01, 'classifie...         0.787032   \n",
            "9   {'classifier__learning_rate': 0.1, 'classifier...         0.799470   \n",
            "10  {'classifier__learning_rate': 0.1, 'classifier...         0.799276   \n",
            "11  {'classifier__learning_rate': 0.1, 'classifier...         0.799058   \n",
            "12  {'classifier__learning_rate': 0.1, 'classifier...         0.798345   \n",
            "13  {'classifier__learning_rate': 0.1, 'classifier...         0.799395   \n",
            "14  {'classifier__learning_rate': 0.1, 'classifier...         0.801476   \n",
            "15  {'classifier__learning_rate': 0.1, 'classifier...         0.797145   \n",
            "16  {'classifier__learning_rate': 0.1, 'classifier...         0.799218   \n",
            "17  {'classifier__learning_rate': 0.1, 'classifier...         0.798371   \n",
            "18  {'classifier__learning_rate': 1.0, 'classifier...         0.770001   \n",
            "19  {'classifier__learning_rate': 1.0, 'classifier...         0.775161   \n",
            "20  {'classifier__learning_rate': 1.0, 'classifier...         0.779448   \n",
            "21  {'classifier__learning_rate': 1.0, 'classifier...         0.750503   \n",
            "22  {'classifier__learning_rate': 1.0, 'classifier...         0.755217   \n",
            "23  {'classifier__learning_rate': 1.0, 'classifier...         0.754270   \n",
            "24  {'classifier__learning_rate': 1.0, 'classifier...         0.733768   \n",
            "25  {'classifier__learning_rate': 1.0, 'classifier...         0.741279   \n",
            "26  {'classifier__learning_rate': 1.0, 'classifier...         0.746848   \n",
            "\n",
            "    std_test_score  \n",
            "0         0.010036  \n",
            "1         0.010036  \n",
            "2         0.010031  \n",
            "3         0.008433  \n",
            "4         0.008477  \n",
            "5         0.008480  \n",
            "6         0.011836  \n",
            "7         0.012359  \n",
            "8         0.012210  \n",
            "9         0.009234  \n",
            "10        0.008274  \n",
            "11        0.008763  \n",
            "12        0.008799  \n",
            "13        0.010218  \n",
            "14        0.009062  \n",
            "15        0.009968  \n",
            "16        0.009188  \n",
            "17        0.009845  \n",
            "18        0.008748  \n",
            "19        0.006788  \n",
            "20        0.003963  \n",
            "21        0.006930  \n",
            "22        0.012220  \n",
            "23        0.007614  \n",
            "24        0.011702  \n",
            "25        0.013629  \n",
            "26        0.011413  \n",
            "\n",
            "Best Hyperparameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_samples_split': 10}\n",
            "Best Mean ROC-AUC Score: 0.8015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the parameter grid for CatBoost\n",
        "param_grid_catboost = {\n",
        "    'classifier__iterations': [100, 200],\n",
        "    'classifier__learning_rate': [0.01, 0.1],\n",
        "    'classifier__depth': [4, 6],\n",
        "    'classifier__random_strength': [0.5, 1.0],  # Added random_strength\n",
        "    'classifier__bagging_temperature': [0.0, 0.5]  # Added bagging_temperature\n",
        "}\n",
        "\n",
        "# Create a CatBoostClassifier instance\n",
        "catboost_model = CatBoostClassifier(verbose=0, random_state=42)\n",
        "\n",
        "# Create a pipeline with the preprocessor and CatBoostClassifier\n",
        "catboost_pipeline = Pipeline([('preprocessor', preprocessor), ('classifier', catboost_model)])\n",
        "\n",
        "# Perform GridSearchCV to find the best hyperparameters\n",
        "grid_search_catboost = GridSearchCV(catboost_pipeline, param_grid_catboost, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "grid_search_catboost.fit(X, y)\n",
        "\n",
        "# Print the results for each hyperparameter combination\n",
        "print(\"\\nCatBoost Hyperparameter Tuning Results:\")\n",
        "results_catboost = pd.DataFrame(grid_search_catboost.cv_results_)\n",
        "print(results_catboost[['params', 'mean_test_score', 'std_test_score']])\n",
        "\n",
        "# Get the best hyperparameters and score for CatBoost\n",
        "best_params_catboost = grid_search_catboost.best_params_\n",
        "best_score_catboost = grid_search_catboost.best_score_\n",
        "\n",
        "print(f\"\\nBest Hyperparameters for CatBoost: {best_params_catboost}\")\n",
        "print(f\"Best Mean ROC-AUC Score for CatBoost: {best_score_catboost:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvOuEaBO60tC",
        "outputId": "c0301c3d-eed5-466a-a531-7119609aea62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CatBoost Hyperparameter Tuning Results:\n",
            "                                               params  mean_test_score  \\\n",
            "0   {'classifier__bagging_temperature': 0.0, 'clas...         0.788666   \n",
            "1   {'classifier__bagging_temperature': 0.0, 'clas...         0.789551   \n",
            "2   {'classifier__bagging_temperature': 0.0, 'clas...         0.802563   \n",
            "3   {'classifier__bagging_temperature': 0.0, 'clas...         0.801909   \n",
            "4   {'classifier__bagging_temperature': 0.0, 'clas...         0.794577   \n",
            "5   {'classifier__bagging_temperature': 0.0, 'clas...         0.793403   \n",
            "6   {'classifier__bagging_temperature': 0.0, 'clas...         0.803177   \n",
            "7   {'classifier__bagging_temperature': 0.0, 'clas...         0.804307   \n",
            "8   {'classifier__bagging_temperature': 0.0, 'clas...         0.793626   \n",
            "9   {'classifier__bagging_temperature': 0.0, 'clas...         0.792958   \n",
            "10  {'classifier__bagging_temperature': 0.0, 'clas...         0.804366   \n",
            "11  {'classifier__bagging_temperature': 0.0, 'clas...         0.802596   \n",
            "12  {'classifier__bagging_temperature': 0.0, 'clas...         0.798610   \n",
            "13  {'classifier__bagging_temperature': 0.0, 'clas...         0.796256   \n",
            "14  {'classifier__bagging_temperature': 0.0, 'clas...         0.802777   \n",
            "15  {'classifier__bagging_temperature': 0.0, 'clas...         0.803526   \n",
            "16  {'classifier__bagging_temperature': 0.5, 'clas...         0.788666   \n",
            "17  {'classifier__bagging_temperature': 0.5, 'clas...         0.789551   \n",
            "18  {'classifier__bagging_temperature': 0.5, 'clas...         0.802563   \n",
            "19  {'classifier__bagging_temperature': 0.5, 'clas...         0.801909   \n",
            "20  {'classifier__bagging_temperature': 0.5, 'clas...         0.794577   \n",
            "21  {'classifier__bagging_temperature': 0.5, 'clas...         0.793403   \n",
            "22  {'classifier__bagging_temperature': 0.5, 'clas...         0.803177   \n",
            "23  {'classifier__bagging_temperature': 0.5, 'clas...         0.804307   \n",
            "24  {'classifier__bagging_temperature': 0.5, 'clas...         0.793626   \n",
            "25  {'classifier__bagging_temperature': 0.5, 'clas...         0.792958   \n",
            "26  {'classifier__bagging_temperature': 0.5, 'clas...         0.804366   \n",
            "27  {'classifier__bagging_temperature': 0.5, 'clas...         0.802596   \n",
            "28  {'classifier__bagging_temperature': 0.5, 'clas...         0.798610   \n",
            "29  {'classifier__bagging_temperature': 0.5, 'clas...         0.796256   \n",
            "30  {'classifier__bagging_temperature': 0.5, 'clas...         0.802777   \n",
            "31  {'classifier__bagging_temperature': 0.5, 'clas...         0.803526   \n",
            "\n",
            "    std_test_score  \n",
            "0         0.011007  \n",
            "1         0.010376  \n",
            "2         0.008753  \n",
            "3         0.010484  \n",
            "4         0.010689  \n",
            "5         0.011547  \n",
            "6         0.010030  \n",
            "7         0.010723  \n",
            "8         0.010415  \n",
            "9         0.011194  \n",
            "10        0.008697  \n",
            "11        0.010769  \n",
            "12        0.012000  \n",
            "13        0.010807  \n",
            "14        0.007980  \n",
            "15        0.010742  \n",
            "16        0.011007  \n",
            "17        0.010376  \n",
            "18        0.008753  \n",
            "19        0.010484  \n",
            "20        0.010689  \n",
            "21        0.011547  \n",
            "22        0.010030  \n",
            "23        0.010723  \n",
            "24        0.010415  \n",
            "25        0.011194  \n",
            "26        0.008697  \n",
            "27        0.010769  \n",
            "28        0.012000  \n",
            "29        0.010807  \n",
            "30        0.007980  \n",
            "31        0.010742  \n",
            "\n",
            "Best Hyperparameters for CatBoost: {'classifier__bagging_temperature': 0.0, 'classifier__depth': 6, 'classifier__iterations': 100, 'classifier__learning_rate': 0.1, 'classifier__random_strength': 0.5}\n",
            "Best Mean ROC-AUC Score for CatBoost: 0.8044\n"
          ]
        }
      ]
    }
  ]
}